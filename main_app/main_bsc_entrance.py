# main_bsc_entrance.py - AstraDB Version ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö BSC Entrance
import os
import uuid
from typing import List

from astrapy import DataAPIClient
from dotenv import load_dotenv
from langchain.callbacks.manager import CallbackManagerForRetrieverRun
from langchain.prompts import PromptTemplate
from langchain.schema import BaseRetriever, Document
from langchain_community.chat_models import ChatOpenAI
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever

load_dotenv()

# -------------------------------
# Embeddings
# -------------------------------
embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

# -------------------------------
# AstraDB Setup
# -------------------------------
ASTRA_TOKEN = os.getenv("ASTRA_DB_APPLICATION_TOKEN")
ASTRA_ENDPOINT = os.getenv("ASTRA_DB_API_ENDPOINT")
ASTRA_KEYSPACE = os.getenv("ASTRA_DB_KEYSPACE", "default_keyspace")
COLLECTION_NAME = "bsc_entrance_embedding"

if not ASTRA_TOKEN or not ASTRA_ENDPOINT:
    print("‚ùå Missing AstraDB credentials in .env")
    exit(1)

client = DataAPIClient(token=ASTRA_TOKEN)
database = client.get_database_by_api_endpoint(ASTRA_ENDPOINT)

try:
    collection = database.get_collection(COLLECTION_NAME)
    print(f"‚úÖ Connected to collection: {COLLECTION_NAME}")
except Exception as e:
    print(f"‚ùå Error accessing collection: {e}")
    exit(1)

# -------------------------------
# Custom Retriever
# -------------------------------
class BSCEntranceRetriever(BaseRetriever):
    def __init__(self, collection, embedding):
        super().__init__()
        self._collection = collection
        self._embedding = embedding
        self._bm25_retriever = None
        self._documents_cache = None

    def _get_relevant_documents(self, query: str, *, run_manager: CallbackManagerForRetrieverRun) -> List[Document]:
        print(f"üîç Searching query: {query}")

        # ‡∏î‡∏∂‡∏á keywords
        query_keywords = self._extract_search_keywords(query)
        print(f"üìù Keywords used for search: {query_keywords}")  # <-- ‡πÅ‡∏Å‡πâ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
        
        # ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        if any(word in query.lower() for word in ["‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", "all", "‡∏ó‡∏∏‡∏Å‡∏Ç‡πà‡∏≤‡∏ß", "‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®"]):
            return self._get_comprehensive_search()

        # Step 1: Text search (BM25)
        text_results = self._text_search(query)

        # Step 2: Vector search
        vector_results = self._vector_search(query)

        # Step 3: Merge results with prioritization
        all_documents = []
        seen_content = set()
        query_keywords = self._extract_search_keywords(query)

        prioritized_docs = []
        regular_docs = []

        for doc in text_results + vector_results:
            if doc.page_content not in seen_content:
                content_lower = doc.page_content.lower()
                has_exact = any(keyword.lower() in content_lower for keyword in query_keywords if len(keyword) >= 3)
                if has_exact:
                    prioritized_docs.append(doc)
                else:
                    regular_docs.append(doc)
                seen_content.add(doc.page_content)

        all_documents = prioritized_docs + regular_docs
        return all_documents[:20]

    def _get_comprehensive_search(self) -> List[Document]:
        print("üöÄ Comprehensive search in BSC Entrance collection...")
        docs = []
        try:
            results = self._collection.find({}, limit=50)
            for r in results:
                docs.append(Document(page_content=r.get("content", ""), metadata=r.get("metadata", {})))
            print(f"üìä Found {len(docs)} documents")
        except Exception as e:
            print(f"‚ùå Error: {e}")
        return docs

    def _vector_search(self, query: str) -> List[Document]:
        docs = []
        try:
            query_vector = self._embedding.embed_query(query)
            results = self._collection.find({}, sort={"$vector": query_vector}, limit=15)
            for r in results:
                docs.append(Document(page_content=r.get("content", ""), metadata=r.get("metadata", {})))
        except Exception as e:
            print(f"‚ùå Vector search error: {e}")
        return docs

    def _ensure_bm25_initialized(self):
        if self._bm25_retriever is None:
            try:
                results = self._collection.find({}, limit=200)
                documents = [Document(page_content=r.get("content", ""), metadata=r.get("metadata", {})) for r in results]
                self._documents_cache = documents
                if documents:
                    self._bm25_retriever = BM25Retriever.from_documents(documents)
                    self._bm25_retriever.k = 15
            except Exception as e:
                print(f"‚ùå BM25 init error: {e}")
                self._bm25_retriever = None

    def _preprocess_query_for_bm25(self, query: str) -> str:
        return query.replace("‡∏Ç‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "").strip()

    def _text_search(self, query: str) -> List[Document]:
        try:
            self._ensure_bm25_initialized()
            if self._bm25_retriever is None:
                return self._fallback_keyword_search(query)
            variants = [query, self._preprocess_query_for_bm25(query)]
            seen = set()
            results = []
            for v in variants:
                docs = self._bm25_retriever.get_relevant_documents(v)
                for d in docs:
                    if d.page_content not in seen:
                        results.append(d)
                        seen.add(d.page_content)
            return results[:15]
        except Exception as e:
            print(f"‚ùå Text search error: {e}")
            return self._fallback_keyword_search(query)

    def _fallback_keyword_search(self, query: str) -> List[Document]:
        results = []
        try:
            keywords = self._extract_search_keywords(query)
            docs = self._collection.find({}, limit=100)
            for r in docs:
                content_lower = r.get("content", "").lower()
                if any(k.lower() in content_lower for k in keywords):
                    results.append(Document(page_content=r.get("content", ""), metadata=r.get("metadata", {})))
        except Exception as e:
            print(f"‚ùå Fallback search error: {e}")
        return results[:15]

    def _extract_search_keywords(self, query: str) -> List[str]:
        import re
        stop_words = ["‡∏Ç‡∏≠", "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡∏Ç‡πà‡∏≤‡∏ß", "‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®", "‡∏î‡∏π", "‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö", "‡πÉ‡∏ô", "‡∏Ç‡∏≠‡∏á", "‡πÅ‡∏•‡∏∞", "‡∏´‡∏£‡∏∑‡∏≠"]
        clean_query = query
        for sw in stop_words:
            clean_query = clean_query.replace(sw, " ")
        clean_query = re.sub(r'\s+', ' ', clean_query).strip()
        keywords = [clean_query] if clean_query else []
        words = query.split()
        for w in words:
            if w not in stop_words and len(w) >= 2:
                keywords.append(w)
        # Remove duplicates
        unique_keywords = []
        for k in keywords:
            if k not in unique_keywords:
                unique_keywords.append(k)
        return unique_keywords

retriever = BSCEntranceRetriever(collection, embedding)

# -------------------------------
# Prompt Template
# -------------------------------
PROMPT = PromptTemplate.from_template("""
‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®, ‡∏Ç‡πà‡∏≤‡∏ß, ‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏Å‡∏™‡∏π‡∏ï‡∏£‡∏Ç‡∏≠‡∏á BSC Entrance (‡∏Ñ‡∏ì‡∏∞‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≠‡∏°‡∏û‡∏¥‡∏ß‡πÄ‡∏ï‡∏≠‡∏£‡πå ‡∏°‡∏Ç.)
‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å BSC Entrance

‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡πâ‡∏ô‡∏≥‡∏°‡∏≤‡∏ï‡∏≠‡∏ö
‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏ß‡πà‡∏≤ "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏© ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

---------------------
{context}
---------------------
‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°: {question}
‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö (‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡πâ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢):
""")

# -------------------------------
# Chat Model
# -------------------------------
openrouter_api_key = os.getenv("OPENROUTER_API_KEY")

if not openrouter_api_key:
    print("‚ö†Ô∏è Warning: OPENROUTER_API_KEY not found, LLM responses will not work")
    llm = None
else:
    llm = ChatOpenAI(
        model="openai/gpt-4o-2024-11-20",
        temperature=0,
        openai_api_key=openrouter_api_key,
        openai_api_base="https://openrouter.ai/api/v1"
    )

# -------------------------------
# Manual QA Chain
# -------------------------------
def manual_qa_chain(question: str) -> str:
    try:
        print(f"üîç Searching question: {question}")
        docs = retriever.get_relevant_documents(question, run_manager=None)
        if not docs:
            return "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏© ‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö"

        # Prepare context
        context_parts = [f"‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà {i+1}:\n{d.page_content}" for i, d in enumerate(docs)]
        context = "\n".join(context_parts)
        formatted_prompt = PROMPT.format(context=context, question=question)

        if llm is None:
            return "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ API key ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM, ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ"

        response = llm.invoke(formatted_prompt)
        return response.content.strip()
    except Exception as e:
        print(f"‚ùå QA chain error: {e}")
        return "‡∏Ç‡∏≠‡πÇ‡∏ó‡∏© ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á"

# -------------------------------
# Interactive Loop
# -------------------------------
if __name__ == "__main__":
    print("üéì ‡∏£‡∏∞‡∏ö‡∏ö‡∏ñ‡∏≤‡∏°-‡∏ï‡∏≠‡∏ö BSC Entrance (AstraDB + Manual QA)")
    print("‡∏û‡∏¥‡∏°‡∏û‡πå 'exit' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\n")
    while True:
        question = input("‚ùì ‡∏ñ‡∏≤‡∏°‡∏°‡∏≤‡πÄ‡∏•‡∏¢: ")
        if question.lower() == "exit":
            break
        answer = manual_qa_chain(question)
        print("ü§ñ ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö:", answer)
        print("-"*50)
